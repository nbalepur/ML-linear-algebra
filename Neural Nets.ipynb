{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### Here we define the functions we need to create a neural network\n",
    "###### Our sigmoid function \\(\\sigma \\) has the derivative of \\(\\sigma \\) * (1 - \\(\\sigma \\))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# sigmoid function for converting values to bernoulli\n",
    "def sigmoid(pred_val):\n",
    "    return 1 / (1 + np.exp(-pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# derivative of sigmoid\n",
    "def sigmoid_derivative(pred_val):\n",
    "    return np.multiply(sigmoid(pred_val), (1 - sigmoid(pred_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### Forward propogation converts the input to the output, creating a \"black box\" of the hidden node layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# forward propogates, storing the value of each node layer in a returned list\n",
    "def forward_prop(inputs, thetas, sample_size):\n",
    "    outputs = []\n",
    "    for theta in thetas:\n",
    "        # adds ones to the beginning of each layer to account for the weight/intercept theta value\n",
    "        inputs = np.hstack((np.ones((sample_size, 1)), np.asarray(inputs)))\n",
    "        # the dot product will get the values of the next layer, we store this value to be used in backpropogation\n",
    "        inputs = inputs @ theta.T\n",
    "        outputs.append(inputs)\n",
    "        # the sigmoid function is called in every layer\n",
    "        inputs = sigmoid(inputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### Back propogation gets the gradient for each set of weights, since multiple thetas are used\n",
    "###### This is basically an application of the \"chain rule\" in Calculus\n",
    "\n",
    "###### Additionally, when the number of classifications is greater than 2, a matrix must be generated with 0's and 1's, just like one vs all logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def back_prop(outputs, actual_val, inputs, thetas, m, num_classifications):\n",
    "    # checks for the number of classifications to adjust the y matrix appropriately\n",
    "    if (num_classifications != 2):\n",
    "        actual_val = (np.eye(num_classifications))[actual_val]\n",
    "    # calculates the differences\n",
    "    diff3 = sigmoid(outputs[-1]) - actual_val\n",
    "    diff2 = np.multiply(diff3 @ thetas[1][:, 1:], sigmoid_derivative(outputs[0]))\n",
    "    # converts to partial derivatives / gradients\n",
    "    Delta1 = diff2.T @ np.hstack((np.ones((m, 1)), np.asarray(inputs)))\n",
    "    Delta2 = diff3.T @ np.hstack((np.ones((m, 1)), np.asarray(sigmoid(outputs[0]))))\n",
    "    # divides by the appropriate constant\n",
    "    return [Delta1 / m, Delta2 / m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### Below is a representation of the neural network architecture we will be using for this first example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3 align=\"center\">\n",
    "    <u>Neural Net Architecture with xnor</u> (or == operator)\n",
    "</h3>\n",
    "<br>\n",
    "<img src=\"xnor_NN.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# defining inputs and outputs\n",
    "xnor_inputs = np.matrix(\"0 0; 1 0; 0 1; 1 1\")\n",
    "xnor_outputs = np.matrix(\"1; 0; 0; 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### Each theta value is represented by the black lines\n",
    "###### The dimension of each theta vector is as follows: <br>\n",
    "\n",
    "###### Let a<sub>i</sub> be the layer of neurons in the ith layer, such that a<sub>0</sub> is the input layer, a<sub>1</sub> is the hidden layer, and a<sub>2</sub> is the output layer\n",
    "###### The dimension of the theta matrix connecting a<sub>i</sub> to a<sub>i+1</sub> is (m x n), where m is the number of neurons in a<sub>i+1</sub>, and n is the number of neurons in a<sub>i</sub> + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# defining theta values with correct dimensions\n",
    "theta_one = np.matrix(np.random.random((2, 3)))\n",
    "theta_two = np.matrix(np.random.random((1, 3)))\n",
    "xnor_thetas = [theta_one, theta_two]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### Our learning rate is especially high in this case because we have a very small sample size (only 4 possible combinations)\n",
    "###### We need our cost gradients to converge quickly\n",
    "###### Therefore in this case, our algorithm can give very innacurate results depending on the choice of thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# defining constants\n",
    "sample_size = xnor_outputs.size\n",
    "num_classifications = 2\n",
    "learning_rate = 5\n",
    "num_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# gradient descent\n",
    "for iteration in range(num_iterations):\n",
    "    outputs = forward_prop(xnor_inputs, xnor_thetas, sample_size)\n",
    "    gradients = back_prop(outputs, xnor_outputs, xnor_inputs, xnor_thetas, sample_size, num_classifications)\n",
    "    xnor_thetas[0] = xnor_thetas[0] - learning_rate * gradients[0]\n",
    "    xnor_thetas[1] = xnor_thetas[1] - learning_rate * gradients[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "[[0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]]\n",
      "\n",
      "Outputs (rounded):\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs:\")\n",
    "print(str(xnor_inputs))\n",
    "print()\n",
    "print(\"Outputs (rounded):\")\n",
    "print(str(np.round(sigmoid(outputs[-1]), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h4>\n",
    "    <u>Utilizing Neural Networks in MNIST Data Set (recognizing handwritten digits)</u>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3 align=\"center\">\n",
    "    <u>Neural Net Architecture for MNIST</u>\n",
    "</h3>\n",
    "<br>\n",
    "<img src=\"mnist_nn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### We will be importing the mnist data from keras, which is forunately almost properly formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing the appropriate libraries\n",
    "import keras\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# importing the data set\n",
    "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### Our constants are similar to before\n",
    "###### However, this a very CPU-intensive algorithm, so we were unable to experiment with a wide range of learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# defining our constants\n",
    "num_classifications = 10\n",
    "m = 2500\n",
    "learning_rate = 2.5\n",
    "num_iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### Due to memory limitations, we were restricted to use 2500 out of the 60,000 provided test images\n",
    "###### Therefore the data was taken from the first 2500 images (we checked that there was an approximately equal count of numbers) <br>\n",
    "###### The data was also reshaped so all the pixels for the images could be represented by a single vector\n",
    "###### Finally, each pixel was divided by 255 (the max pixel value), to normalize the data to floats between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# reshaping and normalizing the inputs to fit our needs\n",
    "mnist_train_inputs = (mnist_x_train[0:m][:][:].reshape(m, 28*28)) / 255\n",
    "mnist_train_outputs = mnist_y_train[0:m]\n",
    "\n",
    "mnist_test_inputs = (mnist_x_test[:][:][:].reshape(mnist_x_test.shape[0], 28*28)) / 255\n",
    "mnist_test_outputs = mnist_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### We defined our thetas using the same convention as above\n",
    "###### We have 28 * 28 inputs (for each pixel), 25 nodes in the hidden layer, and 10 outputs (0 - 9)\n",
    "\n",
    "###### Our thetas now also range between (-0.5 and 0.5), for proper instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# defining theta values with correct dimensions\n",
    "theta_one = np.matrix(np.random.random((25, 785))) - 0.5\n",
    "theta_two = np.matrix(np.random.random((10, 26))) - 0.5\n",
    "mnist_thetas = [theta_one, theta_two]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### We then use the same gradient descent algorithm as in xnor, but swapping variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# gradient descent (run this cell multiple times for improved accuracy)\n",
    "for iteration in range(num_iterations):\n",
    "    outputs = forward_prop(mnist_train_inputs, mnist_thetas, m)\n",
    "    gradients = back_prop(outputs, mnist_train_outputs, mnist_train_inputs, mnist_thetas, m, num_classifications)\n",
    "    mnist_thetas[0] = mnist_thetas[0] - learning_rate * gradients[0]\n",
    "    mnist_thetas[1] = mnist_thetas[1] - learning_rate * gradients[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### We can now see how many of the training images were classified correctly with our forward propogation algorithm\n",
    "###### If we were able to adjust the learning rate and number of iterations, this number would be higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2298 out of 2500 images were identified correctly in training\n",
      "This is about 91.92%\n"
     ]
    }
   ],
   "source": [
    "# forward propogates to get our predicted values\n",
    "predicted_train_outputs = np.argmax(sigmoid(outputs[-1]), axis = 1)\n",
    "num_correct_labels = np.sum(np.diagonal(predicted_train_outputs == mnist_train_outputs))\n",
    "\n",
    "print(str(num_correct_labels) + \" out of \" + str(predicted_train_outputs.size) + \" images were identified correctly in training\")\n",
    "print(\"This is about \" + str(round(100 * (num_correct_labels / predicted_train_outputs.size), 5)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### We then do the same thing for the test training data\n",
    "###### Since the forward propogation algorithm is not very expensive, we are able to use all of the testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8681 out of 10000 images were identified correctly in testing\n",
      "This is about 86.81%\n"
     ]
    }
   ],
   "source": [
    "test_predictions = sigmoid((forward_prop(mnist_test_inputs, mnist_thetas, mnist_x_test.shape[0]))[-1])\n",
    "predicted_test_output_labels = np.argmax(test_predictions, axis = 1)\n",
    "num_correct_test_labels = np.sum(np.diagonal(predicted_test_output_labels == mnist_test_outputs))\n",
    "\n",
    "print(str(num_correct_test_labels) + \" out of \" + str(predicted_test_output_labels.size) + \" images were identified correctly in testing\")\n",
    "print(\"This is about \" + str(round(100 * (num_correct_test_labels / predicted_test_output_labels.size),4)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### We can also print the sigmoid outputs for a random image in the test outputs (run over and over to see prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# imports the appropriate library\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x7F91265CD128>"
      ]
     },
     "execution_count": 29,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction values are: [0.001 0.009 0.021 0.73  0.001 0.022 0.    0.025 0.149 0.002]\n",
      "The computer predicts this number is: 3\n"
     ]
    }
   ],
   "source": [
    "# help from: https://stackoverflow.com/questions/38867869/how-to-create-image-from-numpy-float32-array\n",
    "# gets the random index from the list of test outputs\n",
    "random_index = round(mnist_test_outputs.size * np.random.random())\n",
    "\n",
    "# displays and formats the image correctly\n",
    "data = mnist_test_inputs[random_index].reshape(28, 28)\n",
    "formatted = (data * 255 / np.max(data)).astype('uint8')\n",
    "img = Image.fromarray(formatted)\n",
    "display(img.resize((256,256), PIL.Image.LANCZOS))\n",
    "\n",
    "# gets the predction values and label for that image\n",
    "prediction_arr = np.round(sigmoid(forward_prop(np.matrix(mnist_test_inputs[random_index]), mnist_thetas, 1)[-1]), 3)\n",
    "prediction_label = np.argmax(prediction_arr)\n",
    "\n",
    "print(\"The prediction values are: \" + str(prediction_arr[0]))\n",
    "print(\"The computer predicts this number is: \" + str(prediction_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<u></u>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}